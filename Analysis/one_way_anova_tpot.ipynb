{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import researchpy as rp\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis <font color=blue>after </font> combining RF, DT and SVM into 1C 10 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class (model):\n",
    "    if isinstance(model, str):\n",
    "        model = '{' +'}'.join('{'.join(model.split('{')[1:]).split('}')[0:1]) + '}'\n",
    "        m = ast.literal_eval(model)\n",
    "        if 'classifier:__choice__' in m:\n",
    "            classifier = m['classifier:__choice__']\n",
    "        else:\n",
    "            classifier = ''\n",
    "        return classifier\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "\n",
    "def parse_tpot(directory):\n",
    "    result = pd.DataFrame(columns=['dataset', 'accuracy', 'model', 'precision', 'recall', 'f1score', 'time_budget', 'methods'])\n",
    "    for subdir, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                method = file.split('.')[0].split('_')[2]\n",
    "                time_budget = file.split('.')[0].split('_')[3]\n",
    "                run = []\n",
    "                sub_result = pd.read_csv(os.path.join(subdir, file))\n",
    "                sub_result.rename(columns={'Unnamed: 0': 'dataset'}, inplace = True)\n",
    "                run.append(sub_result[['dataset', 'accuracy_1', 'model_1', 'precision_1', 'recall_1', 'f1score_1']])\n",
    "                run.append(sub_result[['dataset', 'accuracy_2', 'model_2', 'precision_2', 'recall_2', 'f1score_2']])\n",
    "                run.append(sub_result[['dataset', 'accuracy_3', 'model_3', 'precision_3', 'recall_3', 'f1score_3']])\n",
    "                for i in range(3):\n",
    "                    run[i].rename(columns={'accuracy_'+str(i+1): 'accuracy',\n",
    "                                           'model_'+str(i+1): 'model',\n",
    "                                           'precision_'+str(i+1): 'precision',\n",
    "                                           'recall_'+str(i+1): 'recall',\n",
    "                                           'f1score_'+str(i+1): 'f1score'}, inplace=True)\n",
    "                    run[i]['methods'] = str(method)\n",
    "                    run[i]['time_budget'] = int(time_budget)\n",
    "                    result = pd.concat([result, run[i]], axis=0, sort=True, ignore_index=True)\n",
    "    result.model = result.model.apply(get_class)\n",
    "    result = result[~np.isnan(result.f1score)]\n",
    "    return result\n",
    "#parse_tpot(r\"C:\\Users\\HassanEldeeb\\Documents\\GitHub\\AutoMLBenchmarking\\logs_search_space/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HassanEldeeb\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\HassanEldeeb\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(524, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = parse_tpot(r\"C:\\Users\\HassanEldeeb\\Documents\\GitHub\\AutoMLBenchmarking\\logs_search_space/\")\n",
    "df = df[['dataset', 'time_budget', 'methods', 'f1score']]\n",
    "df.methods = df.methods.replace(\"default\", \"fc\")\n",
    "df.methods = df.methods.replace(\"3C\", \"3c\")\n",
    "df.methods = df.methods.replace(\"SVC\", \"1c\")\n",
    "df.methods = df.methods.replace(\"DT\", \"1c\")\n",
    "df.methods = df.methods.replace(\"RF\", \"1c\")\n",
    "df10 = df[df.time_budget==10]\n",
    "df30 = df[df.time_budget==30]\n",
    "df60 = df[df.time_budget==60]\n",
    "fsIs_b = ['vowel', 'openml_phpJNxH0q', 'dataset_31_credit-g', 'dataset_40_sonar']\n",
    "fsIs_m = ['solar-flare_1', 'wine-quality-red', 'dataset_39_ecoli', 'synthetic_control']\n",
    "fsIl_b = ['AirlinesCodrnaAdult', 'MagicTelescope', 'electricity-normalized', 'phpmPOD5A']\n",
    "fsIl_m = ['pokerhand-normalized', 'eye_movements', 'avila-tr']\n",
    "flIs_b = ['audiology', 'arrhythmia', 'AP_Breast_Lung', 'AP_Omentum_Ovary']\n",
    "flIs_m = ['Amazon', 'umistfacescropped', 'phpGUrE90']\n",
    "flIl_b = ['gina_agnostic', 'hiva_agnostic', 'phpZrCzJR', 'phprAeXmK']\n",
    "flIl_m = ['KDDCup99', 'connect-4', 'dataset_60_waveform-5000', 'dataset_186_satimage']\n",
    "df_binary = df[df.dataset.isin(fsIs_b) | df.dataset.isin(fsIl_b) | df.dataset.isin(flIs_b) | df.dataset.isin(flIl_b)]\n",
    "df_multi = df[df.dataset.isin(fsIs_m) | df.dataset.isin(fsIl_m) | df.dataset.isin(flIs_m) | df.dataset.isin(flIl_m)]\n",
    "#df.drop(df[(df.methods=='fc') & ((df.time_budget==30) | (df.time_budget==10))].index, inplace=True)\n",
    "#df.drop(df[(df.methods=='3c') & ((df.time_budget==60) | (df.time_budget==10))].index, inplace=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>N</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "      <th>SE</th>\n",
       "      <th>95% Conf.</th>\n",
       "      <th>Interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>f1score</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.716536</td>\n",
       "      <td>0.268588</td>\n",
       "      <td>0.021436</td>\n",
       "      <td>0.674194</td>\n",
       "      <td>0.758877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Variable      N      Mean        SD        SE  95% Conf.  Interval\n",
       "0  f1score  157.0  0.716536  0.268588  0.021436   0.674194  0.758877"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rp.summary_cont(df10['f1score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>N</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "      <th>SE</th>\n",
       "      <th>95% Conf.</th>\n",
       "      <th>Interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>f1score</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.701214</td>\n",
       "      <td>0.273636</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>0.660149</td>\n",
       "      <td>0.742278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Variable      N      Mean        SD        SE  95% Conf.  Interval\n",
       "0  f1score  173.0  0.701214  0.273636  0.020804   0.660149  0.742278"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rp.summary_cont(df30['f1score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>N</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "      <th>SE</th>\n",
       "      <th>95% Conf.</th>\n",
       "      <th>Interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>f1score</td>\n",
       "      <td>194.0</td>\n",
       "      <td>0.707828</td>\n",
       "      <td>0.270216</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.669564</td>\n",
       "      <td>0.746092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Variable      N      Mean        SD      SE  95% Conf.  Interval\n",
       "0  f1score  194.0  0.707828  0.270216  0.0194   0.669564  0.746092"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rp.summary_cont(df60['f1score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=6.352906547787905, pvalue=0.002232997352526722)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.f_oneway(df10['f1score'][df10['methods'] == '1c'], \n",
    "             df10['f1score'][df10['methods'] == '3c'],\n",
    "             df10['f1score'][df10['methods'] == 'fc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=9.472582128717065, pvalue=0.00012578153876374195)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.f_oneway(df30['f1score'][df30['methods'] == '1c'], \n",
    "             df30['f1score'][df30['methods'] == '3c'],\n",
    "             df30['f1score'][df30['methods'] == 'fc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=11.833643763871235, pvalue=1.4290456768010514e-05)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.f_oneway(df60['f1score'][df60['methods'] == '1c'], \n",
    "             df60['f1score'][df60['methods'] == '3c'],\n",
    "             df60['f1score'][df60['methods'] == 'fc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall model F( 2, 154) =  6.353, p =  0.0022\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>f1score</td>     <th>  R-squared:         </th> <td>   0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   6.353</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 01 Nov 2019</td> <th>  Prob (F-statistic):</th>  <td>0.00223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:24:04</td>     <th>  Log-Likelihood:    </th> <td> -9.6599</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   157</td>      <th>  AIC:               </th> <td>   25.32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   154</td>      <th>  BIC:               </th> <td>   34.49</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>        <td>    0.6523</td> <td>    0.028</td> <td>   23.686</td> <td> 0.000</td> <td>    0.598</td> <td>    0.707</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(methods)[T.3c]</th> <td>    0.1613</td> <td>    0.053</td> <td>    3.045</td> <td> 0.003</td> <td>    0.057</td> <td>    0.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(methods)[T.fc]</th> <td>    0.1359</td> <td>    0.052</td> <td>    2.622</td> <td> 0.010</td> <td>    0.033</td> <td>    0.238</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>19.892</td> <th>  Durbin-Watson:     </th> <td>   2.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  23.936</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.951</td> <th>  Prob(JB):          </th> <td>6.34e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.194</td> <th>  Cond. No.          </th> <td>    3.16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                f1score   R-squared:                       0.076\n",
       "Model:                            OLS   Adj. R-squared:                  0.064\n",
       "Method:                 Least Squares   F-statistic:                     6.353\n",
       "Date:                Fri, 01 Nov 2019   Prob (F-statistic):            0.00223\n",
       "Time:                        22:24:04   Log-Likelihood:                -9.6599\n",
       "No. Observations:                 157   AIC:                             25.32\n",
       "Df Residuals:                     154   BIC:                             34.49\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "Intercept            0.6523      0.028     23.686      0.000       0.598       0.707\n",
       "C(methods)[T.3c]     0.1613      0.053      3.045      0.003       0.057       0.266\n",
       "C(methods)[T.fc]     0.1359      0.052      2.622      0.010       0.033       0.238\n",
       "==============================================================================\n",
       "Omnibus:                       19.892   Durbin-Watson:                   2.225\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               23.936\n",
       "Skew:                          -0.951   Prob(JB):                     6.34e-06\n",
       "Kurtosis:                       3.194   Cond. No.                         3.16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # Fits the model with the interaction term\n",
    "    # This will also automatically include the main effects for each factor\n",
    "    model10 = ols('f1score ~ C(methods)', df10).fit()\n",
    "\n",
    "    # Seeing if the overall model is significant\n",
    "    print(f\"Overall model F({model10.df_model: .0f},{model10.df_resid: .0f}) = {model10.fvalue: .3f}, p = {model10.f_pvalue: .4f}\")\n",
    "    model10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall model F( 2, 170) =  9.473, p =  0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>f1score</td>     <th>  R-squared:         </th> <td>   0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   9.473</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 01 Nov 2019</td> <th>  Prob (F-statistic):</th> <td>0.000126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:24:05</td>     <th>  Log-Likelihood:    </th> <td> -11.635</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   173</td>      <th>  AIC:               </th> <td>   29.27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   170</td>      <th>  BIC:               </th> <td>   38.73</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>        <td>    0.6247</td> <td>    0.027</td> <td>   23.568</td> <td> 0.000</td> <td>    0.572</td> <td>    0.677</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(methods)[T.3c]</th> <td>    0.1753</td> <td>    0.054</td> <td>    3.255</td> <td> 0.001</td> <td>    0.069</td> <td>    0.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(methods)[T.fc]</th> <td>    0.1732</td> <td>    0.047</td> <td>    3.678</td> <td> 0.000</td> <td>    0.080</td> <td>    0.266</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>17.930</td> <th>  Durbin-Watson:     </th> <td>   2.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  21.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.854</td> <th>  Prob(JB):          </th> <td>2.67e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.045</td> <th>  Cond. No.          </th> <td>    3.22</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                f1score   R-squared:                       0.100\n",
       "Model:                            OLS   Adj. R-squared:                  0.090\n",
       "Method:                 Least Squares   F-statistic:                     9.473\n",
       "Date:                Fri, 01 Nov 2019   Prob (F-statistic):           0.000126\n",
       "Time:                        22:24:05   Log-Likelihood:                -11.635\n",
       "No. Observations:                 173   AIC:                             29.27\n",
       "Df Residuals:                     170   BIC:                             38.73\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "Intercept            0.6247      0.027     23.568      0.000       0.572       0.677\n",
       "C(methods)[T.3c]     0.1753      0.054      3.255      0.001       0.069       0.282\n",
       "C(methods)[T.fc]     0.1732      0.047      3.678      0.000       0.080       0.266\n",
       "==============================================================================\n",
       "Omnibus:                       17.930   Durbin-Watson:                   2.152\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               21.065\n",
       "Skew:                          -0.854   Prob(JB):                     2.67e-05\n",
       "Kurtosis:                       3.045   Cond. No.                         3.22\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # Fits the model with the interaction term\n",
    "    # This will also automatically include the main effects for each factor\n",
    "    model30 = ols('f1score ~ C(methods)', df30).fit()\n",
    "\n",
    "    # Seeing if the overall model is significant\n",
    "    print(f\"Overall model F({model30.df_model: .0f},{model30.df_resid: .0f}) = {model30.fvalue: .3f}, p = {model30.f_pvalue: .4f}\")\n",
    "    model30.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall model F( 2, 191) =  11.834, p =  0.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>f1score</td>     <th>  R-squared:         </th> <td>   0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   6.353</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 01 Nov 2019</td> <th>  Prob (F-statistic):</th>  <td>0.00223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:24:06</td>     <th>  Log-Likelihood:    </th> <td> -9.6599</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   157</td>      <th>  AIC:               </th> <td>   25.32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   154</td>      <th>  BIC:               </th> <td>   34.49</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>        <td>    0.6523</td> <td>    0.028</td> <td>   23.686</td> <td> 0.000</td> <td>    0.598</td> <td>    0.707</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(methods)[T.3c]</th> <td>    0.1613</td> <td>    0.053</td> <td>    3.045</td> <td> 0.003</td> <td>    0.057</td> <td>    0.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(methods)[T.fc]</th> <td>    0.1359</td> <td>    0.052</td> <td>    2.622</td> <td> 0.010</td> <td>    0.033</td> <td>    0.238</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>19.892</td> <th>  Durbin-Watson:     </th> <td>   2.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  23.936</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.951</td> <th>  Prob(JB):          </th> <td>6.34e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.194</td> <th>  Cond. No.          </th> <td>    3.16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                f1score   R-squared:                       0.076\n",
       "Model:                            OLS   Adj. R-squared:                  0.064\n",
       "Method:                 Least Squares   F-statistic:                     6.353\n",
       "Date:                Fri, 01 Nov 2019   Prob (F-statistic):            0.00223\n",
       "Time:                        22:24:06   Log-Likelihood:                -9.6599\n",
       "No. Observations:                 157   AIC:                             25.32\n",
       "Df Residuals:                     154   BIC:                             34.49\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "Intercept            0.6523      0.028     23.686      0.000       0.598       0.707\n",
       "C(methods)[T.3c]     0.1613      0.053      3.045      0.003       0.057       0.266\n",
       "C(methods)[T.fc]     0.1359      0.052      2.622      0.010       0.033       0.238\n",
       "==============================================================================\n",
       "Omnibus:                       19.892   Durbin-Watson:                   2.225\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               23.936\n",
       "Skew:                          -0.951   Prob(JB):                     6.34e-06\n",
       "Kurtosis:                       3.194   Cond. No.                         3.16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # Fits the model with the interaction term\n",
    "    # This will also automatically include the main effects for each factor\n",
    "    model60 = ols('f1score ~ C(methods)', df60).fit()\n",
    "\n",
    "    # Seeing if the overall model is significant\n",
    "    print(f\"Overall model F({model60.df_model: .0f},{model60.df_resid: .0f}) = {model60.fvalue: .3f}, p = {model60.f_pvalue: .4f}\")\n",
    "    model10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "===================================================\n",
      "group1 group2 meandiff p-adj   lower  upper  reject\n",
      "---------------------------------------------------\n",
      "    1c     3c   0.1613 0.0077  0.0359 0.2866   True\n",
      "    1c     fc   0.1359 0.0259  0.0132 0.2586   True\n",
      "    3c     fc  -0.0254    0.9 -0.1746 0.1238  False\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "mc = MultiComparison(df10['f1score'], df10['methods'])\n",
    "mc_results = mc.tukeyhsd()\n",
    "print(mc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "===================================================\n",
      "group1 group2 meandiff p-adj   lower  upper  reject\n",
      "---------------------------------------------------\n",
      "    1c     3c   0.1753 0.0039   0.048 0.3027   True\n",
      "    1c     fc   0.1732  0.001  0.0619 0.2845   True\n",
      "    3c     fc  -0.0021    0.9 -0.1462 0.1419  False\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mc = MultiComparison(df30['f1score'], df30['methods'])\n",
    "mc_results = mc.tukeyhsd()\n",
    "print(mc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "===================================================\n",
      "group1 group2 meandiff p-adj   lower  upper  reject\n",
      "---------------------------------------------------\n",
      "    1c     3c   0.1619 0.0027  0.0479 0.2758   True\n",
      "    1c     fc   0.1902  0.001  0.0877 0.2927   True\n",
      "    3c     fc   0.0283 0.8449 -0.0994  0.156  False\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mc = MultiComparison(df60['f1score'], df60['methods'])\n",
    "mc_results = mc.tukeyhsd()\n",
    "print(mc_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis <font color=blue>without </font> combining RF, DT and SVM into 1C 10 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"C:\\Users\\HassanEldeeb\\Documents\\GitHub\\AutoMLBenchmarking\\logs_search_space/skout.xlsx\")\n",
    "df = df[['time_budget', 'methods', 'f1score']]\n",
    "df.methods = df.methods.replace(\"['adaboost', 'bernoulli_nb', 'decision_tree', 'extra_trees', 'gaussian_nb', 'gradient_boosting', 'k_nearest_neighbors', 'lda', 'liblinear_svc', 'libsvm_svc', 'multinomial_nb', 'passive_aggressive', 'qda', 'random_forest', 'sgd']\", \"fc\")\n",
    "df.methods = df.methods.replace(\"['decision_tree', 'libsvm_svc', 'random_forest']\", \"3c\")\n",
    "df.methods = df.methods.replace(\"['libsvm_svc']\", \"svc\")\n",
    "df.methods = df.methods.replace(\"['decision_tree']\", \"dt\")\n",
    "df.methods = df.methods.replace(\"['random_forest']\", \"rf\")\n",
    "df10 = df[df.time_budget==10]\n",
    "df30 = df[df.time_budget==30]\n",
    "df60 = df[df.time_budget==60]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.summary_cont(df10['f1score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.summary_cont(df30['f1score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.summary_cont(df60['f1score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.f_oneway(df10['f1score'][df10['methods'] == '1c'], \n",
    "             df10['f1score'][df10['methods'] == '3c'],\n",
    "             df10['f1score'][df10['methods'] == 'fc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.f_oneway(df30['f1score'][df30['methods'] == '1c'], \n",
    "             df30['f1score'][df30['methods'] == '3c'],\n",
    "             df30['f1score'][df30['methods'] == 'fc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.f_oneway(df60['f1score'][df60['methods'] == '1c'], \n",
    "             df60['f1score'][df60['methods'] == '3c'],\n",
    "             df60['f1score'][df60['methods'] == 'fc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Fits the model with the interaction term\n",
    "    # This will also automatically include the main effects for each factor\n",
    "    model10 = ols('f1score ~ C(methods)', df10).fit()\n",
    "\n",
    "    # Seeing if the overall model is significant\n",
    "    print(f\"Overall model F({model10.df_model: .0f},{model10.df_resid: .0f}) = {model10.fvalue: .3f}, p = {model10.f_pvalue: .4f}\")\n",
    "    model10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Fits the model with the interaction term\n",
    "    # This will also automatically include the main effects for each factor\n",
    "    model30 = ols('f1score ~ C(methods)', df30).fit()\n",
    "\n",
    "    # Seeing if the overall model is significant\n",
    "    print(f\"Overall model F({model30.df_model: .0f},{model30.df_resid: .0f}) = {model30.fvalue: .3f}, p = {model30.f_pvalue: .4f}\")\n",
    "    model30.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Fits the model with the interaction term\n",
    "    # This will also automatically include the main effects for each factor\n",
    "    model60 = ols('f1score ~ C(methods)', df60).fit()\n",
    "\n",
    "    # Seeing if the overall model is significant\n",
    "    print(f\"Overall model F({model60.df_model: .0f},{model60.df_resid: .0f}) = {model60.fvalue: .3f}, p = {model60.f_pvalue: .4f}\")\n",
    "    model10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "mc = MultiComparison(df10['f1score'], df10['methods'])\n",
    "mc_results = mc.tukeyhsd()\n",
    "print(mc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = MultiComparison(df30['f1score'], df30['methods'])\n",
    "mc_results = mc.tukeyhsd(model30.f_pvalue)\n",
    "print(mc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = MultiComparison(df60['f1score'], df60['methods'])\n",
    "mc_results = mc.tukeyhsd(model60.f_pvalue)\n",
    "print(mc_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
